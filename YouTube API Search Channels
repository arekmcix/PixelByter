from googleapiclient.discovery import build
from google_auth_oauthlib.flow import InstalledAppFlow
import datetime
import html  # Importing html module for decoding
import os
import pytz  # For handling time zones

def get_authenticated_service():
    flow = InstalledAppFlow.from_client_secrets_file(
        'C:/Users/arekmcix/Downloads/client_secret_tsbio9qvu74q5kn5mh635cvpb7657vcb.apps.googleusercontent.com.json', 
        scopes=['https://www.googleapis.com/auth/youtube.readonly', 'https://www.googleapis.com/auth/spreadsheets'])
    credentials = flow.run_local_server()
    return build('youtube', 'v3', credentials=credentials), build('sheets', 'v4', credentials=credentials)

def fetch_youtube_data(youtube_service, query):
    days_ago = datetime.datetime.now(datetime.timezone.utc) - datetime.timedelta(days=5)
    published_after = days_ago.strftime('%Y-%m-%dT%H:%M:%SZ')

    rows = []
    next_page_token = None
    max_results = 100

    while len(rows) < max_results:
        response = youtube_service.search().list(
            part='snippet',
            q=query,
            type='video',
            maxResults=50,  # API maximum
            pageToken=next_page_token,
            publishedAfter=published_after,
            relevanceLanguage='en'
        ).execute()

        for item in response['items']:
            video_id = item['id']['videoId']
            channel_title = html.unescape(item['snippet']['channelTitle'])
            video_title = html.unescape(item['snippet']['title'])
            published_date = item['snippet']['publishedAt'][:10]
            video_url = f'https://www.youtube.com/watch?v={video_id}'

            video_response = youtube_service.videos().list(part='statistics', id=video_id).execute()
            view_count = int(video_response['items'][0]['statistics'].get('viewCount', 0))

            rows.append([channel_title, video_title, published_date, view_count, video_url])

            if len(rows) >= max_results:
                break

        next_page_token = response.get('nextPageToken')
        if not next_page_token:
            break  # Exit loop if no more pages

    rows = sorted(rows, key=lambda x: x[3], reverse=True)
    return rows

def update_sheet(sheets_service, spreadsheet_id, data):
    headers = ['Channel Title', 'Video Title', 'Published Date', 'View Count', 'Video URL']
    data.insert(0, headers)
    
    sheet = sheets_service.spreadsheets()
    update_body = {'values': data}
    result = sheet.values().update(
        spreadsheetId=spreadsheet_id, range='Days',
        valueInputOption='RAW', body=update_body
    ).execute()
    print('Sheet updated: ', result)

def main():
    query = 'Davos'  # Replace with your search query
    SPREADSHEET_ID = '1eMLgKWMAA-t7MHqN4eebIY8TlbZDMwOYy2WXHM'

    youtube_service, sheets_service = get_authenticated_service()
    youtube_data = fetch_youtube_data(youtube_service, query)
    update_sheet(sheets_service, SPREADSHEET_ID, youtube_data)

if __name__ == '__main__':
    main()
